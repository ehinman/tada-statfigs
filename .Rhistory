stn = wqTools::assignPolys(stn,wqTools::au_poly,lat="LatitudeMeasure", long = "LongitudeMeasure", columns = c("ASSESS_ID","AU_NAME","AU_Type","AU_DESCRIP"))
stn = wqTools::assignPolys(stn,wqTools::bu_poly,lat="LatitudeMeasure", long = "LongitudeMeasure", columns = c("R317Descrp","bu_class"))
stn = wqTools::assignPolys(stn,wqTools::ut_poly,lat="LatitudeMeasure", long = "LongitudeMeasure")
stn = wqTools::assignPolys(stn,wqTools::ss_poly, lat="LatitudeMeasure", long = "LongitudeMeasure")
# stn = wqTools::assignPolys(stn,wqTools::hnnc_poly, lat="LatitudeMeasure", long = "LongitudeMeasure")
stn = wqTools::assignPolys(stn,wqTools::wmu_poly, lat="LatitudeMeasure", long = "LongitudeMeasure")
###Spatial rejections
rej_reasons_spat=data.frame(matrix(nrow=0,ncol=2))
#Reject by is.na(AU)
reason_n=data.frame(MonitoringLocationIdentifier=subset(stn, is.na(stn$ASSESS_ID))$MonitoringLocationIdentifier)
if(dim(reason_n)[1]>0){
reason_n$reason="Undefined AU"
rej_reasons_spat=rbind(rej_reasons_spat,reason_n)}
#Reject by is.na(STATE_NAME)
reason_n=data.frame(MonitoringLocationIdentifier=subset(stn, is.na(stn$jurisdict))$MonitoringLocationIdentifier)
if(dim(reason_n)[1]>0){
reason_n$reason="Non-jurisdictional: out of state or within tribal boundaries"
rej_reasons_spat=rbind(rej_reasons_spat,reason_n)}
#Reject by GSL poly
reason_n=data.frame(MonitoringLocationIdentifier=subset(stn, stn$AU_NAME%in%c('Gilbert Bay','Gunnison Bay','Farmington Bay','Bear River Bay'))$MonitoringLocationIdentifier)
if(dim(reason_n)[1]>0){
reason_n$reason="GSL assessed through separate program"
rej_reasons_spat=rbind(rej_reasons_spat,reason_n)}
#Remove unneeded spatial join columns
stn=stn[,!names(stn)%in%c("jurisdict")]
#Reject where MonitoringLocationTypeName is a canal type & AU_Type!="Canal"
reason_n=data.frame(MonitoringLocationIdentifier=subset(stn, stn$MonitoringLocationTypeName%in%c("Stream: Canal","Stream: Ditch","Canal Transport","Canal Drainage","Canal Irrigation")&!stn$AU_Type%in%c("Canal"))$MonitoringLocationIdentifier)
if(dim(reason_n)[1]>0){
reason_n$reason="Non-assessed canal or ditch"
rej_reasons_spat=rbind(rej_reasons_spat,reason_n)}
#Reject where MonitoringLocationTypeName is a stream or spring type & AU_Type!="River/Stream"
reason_n=data.frame(MonitoringLocationIdentifier=subset(stn, stn$MonitoringLocationTypeName%in%c("Stream","River/Stream","River/Stream Intermittent","River/Stream Perennial","Spring")&!stn$AU_Type%in%c("River/Stream","Canal"))$MonitoringLocationIdentifier)
if(dim(reason_n)[1]>0){
reason_n$reason="Stream or spring site type in non-River/Stream AU"
rej_reasons_spat=rbind(rej_reasons_spat,reason_n)}
names(rej_reasons_spat)=c("MonitoringLocationIdentifier","Reason")
rej_reasons_spat$ReasonType="Spatial"
rej_reasons_spat$FLAG="REJECT"
head(rej_reasons_spat)
print("Spatial site rejection reason count:")
print(table(rej_reasons_spat$Reason))
#Set stn IR_FLAG and reason for spatial site rejections
stn$IR_FLAG[stn$MonitoringLocationIdentifier %in% rej_reasons_spat$MonitoringLocationIdentifier]="REJECT"
table(stn$IR_FLAG)
######################
###Duplicate checks###
######################
#Splitting off rejected sites prior to other spatial analyses (including all previously accepted/merged sites allows calc of distances including previously reviewed sites.)
accept_review=stn[stn$IR_FLAG!="REJECT",]
rejected=stn[stn$IR_FLAG=="REJECT",]
class(accept_review$IR_FLAG)
table(accept_review$IR_FLAG)
sum(table(accept_review$IR_FLAG))
#Count MLIDs, add as column to accept_review, MLID_Count>1 means duplicated MLID
accept_review$MLID_Count=as.vector(table(accept_review$MonitoringLocationIdentifier)[accept_review$MonitoringLocationIdentifier])
#Count Latitudes, add as column to accept_review, Lat_Count>1 means duplicated lat
accept_review$Lat_Count=as.vector(table(accept_review$LatitudeMeasure))[as.factor(accept_review$LatitudeMeasure)]
#Count Longitudes, add as column to accept_review, Long_Count>1 means duplicated long
accept_review$Long_Count=as.vector(table(accept_review$LongitudeMeasure))[as.factor(accept_review$LongitudeMeasure)]
#Re-appending rejected data
stn=plyr::rbind.fill(accept_review,rejected)
table(stn$IR_FLAG)
sum(table(stn$IR_FLAG))
rm(accept_review)
rm(rejected)
stn$ValidationType="AUTO"
#Spatial review flags & reasons (Apply to stn only)
#Populate stn$MLID & lat/long for new sites w/ no duplicate MLIDS, lats, longs, and 0 other sites w/in 100m (IR_FLAG=="REVIEW" for all non-rejected new sites at this point)
stn$IR_MLID = ifelse(stn$IR_FLAG=="REVIEW"&stn$MLID_Count==1&stn$Lat_Count==1&stn$Long_Count==1,as.vector(stn$MonitoringLocationIdentifier),"REVIEW")
stn$IR_MLNAME = ifelse(stn$IR_FLAG=="REVIEW"&stn$MLID_Count==1&stn$Lat_Count==1&stn$Long_Count==1,as.vector(stn$MonitoringLocationName),NA)
stn$IR_Lat = ifelse(stn$IR_FLAG=="REVIEW"&stn$MLID_Count==1&stn$Lat_Count==1&stn$Long_Count==1,stn$LatitudeMeasure,NA)
stn$IR_Long = ifelse(stn$IR_FLAG=="REVIEW"&stn$MLID_Count==1&stn$Lat_Count==1&stn$Long_Count==1,stn$LongitudeMeasure,NA)
#Populate rejected MLID, lat, and long w/ REJECT
stn$IR_MLID = ifelse(stn$IR_FLAG=="REJECT","REJECT",as.vector(stn$IR_MLID))
stn$IR_MLNAME = ifelse(stn$IR_FLAG=="REJECT","REJECT",as.vector(stn$IR_MLNAME))
stn$IR_Lat = ifelse(stn$IR_FLAG=="REJECT",NA,stn$IR_Lat)
stn$IR_Long = ifelse(stn$IR_FLAG=="REJECT",NA,stn$IR_Long)
#Review reasons
review_reasons=data.frame(matrix(nrow=0,ncol=2))
#MLID, lat/long, and site 50 m counts
reason_n=data.frame(MonitoringLocationIdentifier=subset(stn, stn$MLID_Count>1)$MonitoringLocationIdentifier)
if(dim(reason_n)[1]>0){
reason_n$reason="Duplicated MLID"
review_reasons=rbind(review_reasons,reason_n)}
reason_n=data.frame(MonitoringLocationIdentifier=subset(stn, stn$Lat_Count>1|stn$Long_Count>1)$MonitoringLocationIdentifier)
if(dim(reason_n)[1]>0){
reason_n$reason="Duplicated lat or long"
review_reasons=rbind(review_reasons,reason_n)}
#MonitoringLocationTypeName is a stream or spring type & AU_Type=="Canal"
reason_n=data.frame(MonitoringLocationIdentifier=subset(stn, stn$MonitoringLocationTypeName%in%c("Stream","River/Stream","River/Stream Intermittent","River/Stream Perennial","Spring")& stn$AU_Type%in%c("Canal"))$MonitoringLocationIdentifier)
if(dim(reason_n)[1]>0){
reason_n$reason="Stream or spring site type in canal AU type"
review_reasons=rbind(review_reasons,reason_n)}
#MonitoringLocationTypeName is a lake type & AU_Type!="Reservoir/Lake"
reason_n=data.frame(MonitoringLocationIdentifier=subset(stn, stn$MonitoringLocationTypeName%in%c("Lake, Reservoir, Impoundment","Lake","Reservoir")& !stn$AU_Type%in%c("Reservoir/Lake"))$MonitoringLocationIdentifier)
if(dim(reason_n)[1]>0){
reason_n$reason="MLID type is lake/reservoir, but AU_Type is not - potential new AU needed"
review_reasons=rbind(review_reasons,reason_n)}
#Rename review reason columns
names(review_reasons)=c("MonitoringLocationIdentifier","Reason")
review_reasons$ReasonType="Spatial"
review_reasons$FLAG="REVIEW"
print("Spatial site review reason count:")
print(table(review_reasons$Reason))
# Convert all NA AU types to Undefined, change beneficial use column name, add Review Comment Column
stn$AU_Type[is.na(stn$AU_Type)]="Undefined"
names(stn)[names(stn)=="bu_class"] = "BEN_CLASS"
names(stn)[names(stn)=="ss_descrp"] = "ss_R317Descrp"
#rbind reasons together
reasons_all=rbind(rej_reasons_att,rej_reasons_spat, review_reasons)
#Populate ACCEPT for new sites w/ no duplicate MLIDS, lats, longs, and 0 other sites w/in 100m (IR_FLAG=="REVIEW" for all non-rejected new sites at this point)
stn=within(stn,{
IR_FLAG[!MonitoringLocationIdentifier %in% reasons_all$MonitoringLocationIdentifier &IR_FLAG!="REJECT" & MLID_Count==1 & Lat_Count==1 & Long_Count==1]<-"ACCEPT"
})
stn=within(stn,{
IR_COMMENT[IR_FLAG=="REJECT" & ValidationType=="AUTO"]="Automatically flagged for rejection"
IR_COMMENT[IR_FLAG=="REVIEW" & ValidationType=="AUTO"]="Automatically flagged for review"
IR_COMMENT[IR_FLAG=="ACCEPT" & ValidationType=="AUTO"]="Automatically accepted"
})
print("Applying manual site rejections...")
# Export master site file
writexl::write_xlsx(list(sites=stn, reasons=reasons_all),
"site_review_file.xlsx", format_headers=F, col_names=T)
irTools::siteValApp()
irTools::siteValApp()
irTools::siteValApp()
irTools::siteValApp()
irTools::siteValApp()
# Install TADA
if(!"remotes"%in%installed.packages()){
install.packages("remotes")
}
remotes::install_github("USEPA/TADA", ref="develop")
# Load tidyverse
if(!"tidyverse"%in%installed.packages()){
install.packages("tidyverse")
}
library(tidyverse)
dataset_0 = TADA::TADAdataRetrieval(
startDate = "2020-03-14",
endDate = "null",
countycode = "null",
huc = "null",
siteid = "null",
siteType = "null",
characteristicName = "null",
characteristicType = "null",
sampleMedia = "null",
statecode = "IA",
organization = "null",
project = "null",
applyautoclean = TRUE
)
dim(dataset_0)
TADA::fieldCounts(dataset_0, display = "key")
TADA::fieldCounts(dataset_0, display = "all")
all_result_num = dim(dataset_0)[1]
removed = dataset_0%>%dplyr::filter(!TADA.ActivityMediaName%in%c("WATER"))
unique(removed$TADA.ActivityMediaName)
dataset = dataset_0%>%dplyr::filter(TADA.ActivityMediaName%in%c("WATER"))
# check result numbers after split
final_result_num = dim(dataset)[1] + dim(removed)[1]
# always good to do a dimension check
if(!all_result_num==final_result_num){
print("Help! Results do not add up between dataset and removed after media filter.")
}
TADA::fieldValuesTable(dataset,field="ActivityTypeCode")
TADA::fieldValuesPie(dataset,field="ActivityTypeCode")
TADA::fieldValuesTable(dataset,field="TADA.ResultMeasureValueDataTypes.Flag")
wrong_datatype = dataset%>%filter(!TADA.ResultMeasureValueDataTypes.Flag%in%c("Numeric","Less Than","Greater Than","Approximate Value","Percentage","Comma-Separated Numeric","Numeric Range - Averaged","Result Value/Unit Copied from Detection Limit"))
check = unique(wrong_datatype[,c("TADA.CharacteristicName","ResultMeasureValue","TADA.ResultMeasureValue", "ResultMeasure.MeasureUnitCode","TADA.ResultMeasure.MeasureUnitCode","TADA.ResultMeasureValueDataTypes.Flag","DetectionQuantitationLimitMeasure.MeasureValue","TADA.DetectionQuantitationLimitMeasure.MeasureValue", "DetectionQuantitationLimitMeasure.MeasureUnitCode","TADA.DetectionQuantitationLimitMeasure.MeasureUnitCode")])
View(check)
dataset = dataset%>%filter(TADA.ResultMeasureValueDataTypes.Flag%in%c("Numeric","Less Than","Greater Than","Approximate Value","Percentage","Comma-Separated Numeric","Numeric Range - Averaged","Result Value/Unit Copied from Detection Limit"))
removed = plyr::rbind.fill(removed, wrong_datatype)
rm(wrong_datatype, check)
# check result numbers after split
current_result_num = dim(dataset)[1] + dim(removed)[1]
# always good to do a dimension check
if(!all_result_num==current_result_num){
print("Help! Results do not add up between dataset and removed after data types filter.")
}
TADA::fieldValuesPie(dataset, field = "TADA.CensoredData.Flag")
problem_censored = dataset%>%dplyr::filter(!TADA.CensoredData.Flag%in%c("Non-Detect","Over-Detect","Other","Uncensored"))
dataset = dataset%>%dplyr::filter(TADA.CensoredData.Flag%in%c("Non-Detect","Over-Detect","Other", "Uncensored"))
removed = plyr::rbind.fill(removed, problem_censored)
rm(problem_censored)
# check result numbers after split
current_result_num = dim(dataset)[1] + dim(removed)[1]
# always good to do a dimension check
if(!all_result_num==current_result_num){
print("Help! Results do not add up between dataset and removed after censored data filter.")
}
# display full table
nrow = length(unique(dataset$TADA.CharacteristicName))
# get table of characteristics with number of results, sites, and organizations
dataset%>%dplyr::group_by(TADA.CharacteristicName)%>%dplyr::summarise(Result_Count = length(ResultIdentifier), Site_Count = length(unique(MonitoringLocationIdentifier)), Org_Count = length(unique(OrganizationIdentifier)))%>%dplyr::arrange(desc(Result_Count))%>%print(n = nrow)
TADA::fieldValuesPie(dataset, field = "TADA.ResultSampleFractionText", characteristicName = "TEMPERATURE, WATER")
TADA::TADAOverviewMap(dataset)
TADA::fieldValuesPie(dataset, field = "MonitoringLocationTypeName")
# before...
TADA::fieldValuesTable(dataset, field = "TADA.ResultMeasure.MeasureUnitCode")%>%dplyr::arrange(desc(Count))
# convert units
dataset = TADA::ConvertResultUnits(dataset, transform = TRUE)
# after!
TADA::fieldValuesTable(dataset, field = "TADA.ResultMeasure.MeasureUnitCode")%>%dplyr::arrange(desc(Count))
qaqc_ref = TADA::GetWQXCharValRef()
head(qaqc_ref)
unique(qaqc_ref$Type)
dataset_flags = TADA::InvalidFraction(dataset, clean = FALSE, errorsonly = FALSE)
dataset_flags = TADA::InvalidSpeciation(dataset_flags, clean = "none", errorsonly = FALSE)
dataset_flags = TADA::InvalidResultUnit(dataset_flags, clean = "none", errorsonly = FALSE)
dataset_flags = TADA::QualityControlActivity(dataset_flags, clean = FALSE, errorsonly = FALSE)
# check result numbers after split
current_result_num = dim(dataset_flags)[1] + dim(removed)[1]
# always good to do a dimension check
if(!all_result_num==current_result_num){
print("Help! Results do not add up between dataset and removed after running flagging functions.")
}
TADA::fieldValuesPie(dataset_flags, field = "TADA.SampleFraction.Flag")
TADA::fieldValuesPie(dataset_flags, field = "TADA.MethodSpeciation.Flag")
TADA::fieldValuesPie(dataset_flags, field = "TADA.ResultUnit.Flag")
TADA::fieldValuesPie(dataset_flags, field = "TADA.ActivityType.Flag")
dimCheck <- function(all_result_num, pass_data, fail_data, checkName){
# check result numbers after split
final_result_num = dim(pass_data)[1] + dim(fail_data)[1]
# always good to do a dimension check
if(!all_result_num==final_result_num){
print(paste0("Help! Results do not add up between dataset and removed after ",checkName,"."))
}
}
# check result numbers
all_result_num = dim(dataset_0)[1]
# remove data with media type that is not water
removed = dataset_0%>%dplyr::filter(!TADA.ActivityMediaName%in%c("WATER"))
# what other media types exist in dataset?
unique(removed$TADA.ActivityMediaName)
# clean dataset contains only water
dataset = dataset_0%>%dplyr::filter(TADA.ActivityMediaName%in%c("WATER"))
dimCheck(all_result_num, dataset, removed, checkName = "Activity Media")
# defining a dimension check function that compares removed and retained data dimensions against the initial data input
dimCheck <- function(all_result_num, pass_data, fail_data, checkName){
# check result numbers after split
final_result_num = dim(pass_data)[1] + dim(fail_data)[1]
# always good to do a dimension check
if(!all_result_num==final_result_num){
print(paste0("Help! Results do not add up between dataset and removed after ",checkName,"."))
}else{print("Dimensions check out! Zero results created or destroyed.")}
}
dimCheck(all_result_num, dataset, removed, checkName = "Activity Media")
TADA::fieldValuesTable(dataset,field="ActivityTypeCode")
TADA::fieldValuesPie(dataset,field="ActivityTypeCode")
# take a look at datatypes
TADA::fieldValuesTable(dataset,field="TADA.ResultMeasureValueDataTypes.Flag")
# these are all of the NOT allowable data types in the dataset.
wrong_datatype = dataset%>%filter(!TADA.ResultMeasureValueDataTypes.Flag%in%c("Numeric","Less Than","Greater Than","Approximate Value","Percentage","Comma-Separated Numeric","Numeric Range - Averaged","Result Value/Unit Copied from Detection Limit"))
# take a look at the difficult data types - do they make sense?
check = unique(wrong_datatype[,c("TADA.CharacteristicName","ResultMeasureValue","TADA.ResultMeasureValue", "ResultMeasure.MeasureUnitCode","TADA.ResultMeasure.MeasureUnitCode","TADA.ResultMeasureValueDataTypes.Flag","DetectionQuantitationLimitMeasure.MeasureValue","TADA.DetectionQuantitationLimitMeasure.MeasureValue", "DetectionQuantitationLimitMeasure.MeasureUnitCode","TADA.DetectionQuantitationLimitMeasure.MeasureUnitCode")])
dataset = dataset%>%filter(TADA.ResultMeasureValueDataTypes.Flag%in%c("Numeric","Less Than","Greater Than","Approximate Value","Percentage","Comma-Separated Numeric","Numeric Range - Averaged","Result Value/Unit Copied from Detection Limit"))
removed = plyr::rbind.fill(removed, wrong_datatype)
rm(wrong_datatype, check)
# check result numbers after split
current_result_num = dim(dataset)[1] + dim(removed)[1]
# always good to do a dimension check
if(!all_result_num==current_result_num){
print("Help! Results do not add up between dataset and removed after data types filter.")
}
dimCheck(all_result_num, dataset, removed, checkName = "Censored Data")
dimCheck(all_result_num, dataset, removed, checkName = "Result Format")
TADA::fieldValuesPie(dataset, field = "TADA.CensoredData.Flag")
problem_censored = dataset%>%dplyr::filter(!TADA.CensoredData.Flag%in%c("Non-Detect","Over-Detect","Other","Uncensored"))
dataset = dataset%>%dplyr::filter(TADA.CensoredData.Flag%in%c("Non-Detect","Over-Detect","Other", "Uncensored"))
removed = plyr::rbind.fill(removed, problem_censored)
rm(problem_censored)
dimCheck(all_result_num, dataset, removed, checkName = "Censored Data")
dataset_flags = TADA::InvalidFraction(dataset, clean = FALSE, errorsonly = FALSE)
dataset_flags = TADA::InvalidSpeciation(dataset_flags, clean = "none", errorsonly = FALSE)
dataset_flags = TADA::InvalidResultUnit(dataset_flags, clean = "none", errorsonly = FALSE)
dataset_flags = TADA::QualityControlActivity(dataset_flags, clean = FALSE, errorsonly = FALSE)
dimCheck(all_result_num, dataset_flags, removed, checkName = "Run Flag Functions")
# grab all the flagged results from the four functions
problem_flagged = dataset_flags%>%filter(TADA.SampleFraction.Flag=="Invalid"|TADA.MethodSpeciation.Flag=="Invalid"|TADA.ResultUnit.Flag=="Invalid"|!TADA.ActivityType.Flag%in%("Non_QC"))
dataset_flags = dataset_flags%>%dplyr::filter(!ResultIdentifier%in%problem_flagged$ResultIdentifier)
removed = plyr::rbind.fill(removed, problem_flagged)
rm(problem_flagged)
dimCheck(all_result_num, dataset_flags, removed, checkName = "Filter Flag Functions")
dataset_cens = TADA::simpleCensoredMethods(dataset_flags, nd_method = "multiplier",nd_multiplier = 0.5, od_method = "as-is")
# before
TADA::fieldValuesTable(dataset_flags, field = "TADA.ResultMeasureValueDataTypes.Flag")
# after
TADA::fieldValuesTable(dataset_cens, field = "TADA.ResultMeasureValueDataTypes.Flag")
# trusty field values table - lets just look at the first few entries with the most associated records
TADA::fieldValuesTable(dataset_cens, field = "TADA.ComparableDataIdentifier")%>%dplyr::arrange(desc(Count))%>%head()
# Look at a histogram, boxplot, and stats for TADA.ComparableDataIdentifier(s) of your choice.
comp_data_id = "TEMPERATURE, WATER_NA_NA_DEG C"
plot_data = subset(dataset_cens, dataset_cens$TADA.ComparableDataIdentifier%in%comp_data_id)
TADA::TADA_hist(plot_data, id_col = "TADA.ComparableDataIdentifier")
TADA::TADA_boxplot(plot_data, id_col = "TADA.ComparableDataIdentifier")
TADA::TADA_stats(plot_data)
# download TADA Shiny repository
remotes::install_github("USEPA/TADAShiny", ref = "develop", dependencies = TRUE)
# launch the app locally.
TADAShiny::run_app()
# uncomment if internet not working
# load("TADA_training_dataset.Rdata")
dim(dataset_0)
# different columns displayed in table
TADA::fieldCounts(dataset_0, display = "key")
TADA::fieldCounts(dataset_0, display = "all")
# defining a dimension check function that compares removed and retained data dimensions against the initial data input
dimCheck <- function(all_result_num, pass_data, fail_data, checkName){
# check result numbers after split
final_result_num = dim(pass_data)[1] + dim(fail_data)[1]
# always good to do a dimension check
if(!all_result_num==final_result_num){
print(paste0("Help! Results do not add up between dataset and removed after ",checkName,"."))
}else{print("Dimensions check out! Zero results created or destroyed.")}
}
# check result numbers
all_result_num = dim(dataset_0)[1]
# remove data with media type that is not water
removed = dataset_0%>%dplyr::filter(!TADA.ActivityMediaName%in%c("WATER"))%>%dplyr::mutate(TADA.RemovalReason = "Activity media is not water.")
# what other media types exist in dataset?
unique(removed$TADA.ActivityMediaName)
# clean dataset contains only water
dataset = dataset_0%>%dplyr::filter(TADA.ActivityMediaName%in%c("WATER"))
dimCheck(all_result_num, dataset, removed, checkName = "Activity Media")
# defining a dimension check function that compares removed and retained data dimensions against the initial data input
dimCheck <- function(all_result_num, pass_data, fail_data, checkName){
# check result numbers after split
final_result_num = dim(pass_data)[1] + dim(fail_data)[1]
# always good to do a dimension check
if(!all_result_num==final_result_num){
print(paste0("Help! Results do not add up between dataset and removed after ",checkName,"."))
}else{print("Good to go. Zero results created or destroyed.")}
}
# check result numbers
all_result_num = dim(dataset_0)[1]
# remove data with media type that is not water
removed = dataset_0%>%dplyr::filter(!TADA.ActivityMediaName%in%c("WATER"))%>%dplyr::mutate(TADA.RemovalReason = "Activity media is not water.")
# what other media types exist in dataset?
unique(removed$TADA.ActivityMediaName)
# clean dataset contains only water
dataset = dataset_0%>%dplyr::filter(TADA.ActivityMediaName%in%c("WATER"))
dimCheck(all_result_num, dataset, removed, checkName = "Activity Media")
TADA::fieldValuesTable(dataset,field="ActivityTypeCode")
TADA::fieldValuesPie(dataset,field="ActivityTypeCode")
# take a look at datatypes
TADA::fieldValuesTable(dataset,field="TADA.ResultMeasureValueDataTypes.Flag")
# these are all of the NOT allowable data types in the dataset.
wrong_datatype = dataset%>%filter(!TADA.ResultMeasureValueDataTypes.Flag%in%c("Numeric","Less Than","Greater Than","Approximate Value","Percentage","Comma-Separated Numeric","Numeric Range - Averaged","Result Value/Unit Copied from Detection Limit"))%>%dplyr::mutate(TADA.RemovalReason = "Result value type cannot be converted to numeric or no detection limit values provided.")
# take a look at the difficult data types - do they make sense?
check = unique(wrong_datatype[,c("TADA.CharacteristicName","ResultMeasureValue","TADA.ResultMeasureValue", "ResultMeasure.MeasureUnitCode","TADA.ResultMeasure.MeasureUnitCode","TADA.ResultMeasureValueDataTypes.Flag","DetectionQuantitationLimitMeasure.MeasureValue","TADA.DetectionQuantitationLimitMeasure.MeasureValue", "DetectionQuantitationLimitMeasure.MeasureUnitCode","TADA.DetectionQuantitationLimitMeasure.MeasureUnitCode")])
dataset = dataset%>%filter(TADA.ResultMeasureValueDataTypes.Flag%in%c("Numeric","Less Than","Greater Than","Approximate Value","Percentage","Comma-Separated Numeric","Numeric Range - Averaged","Result Value/Unit Copied from Detection Limit"))
removed = plyr::rbind.fill(removed, wrong_datatype)
rm(wrong_datatype, check)
dimCheck(all_result_num, dataset, removed, checkName = "Result Format")
TADA::fieldValuesPie(dataset, field = "TADA.CensoredData.Flag")
problem_censored = dataset%>%dplyr::filter(!TADA.CensoredData.Flag%in%c("Non-Detect","Over-Detect","Other","Uncensored"))%>%dplyr::mutate(TADA.RemovalReason = "Detection limit information contains errors or missing information.")
dataset = dataset%>%dplyr::filter(TADA.CensoredData.Flag%in%c("Non-Detect","Over-Detect","Other", "Uncensored"))
removed = plyr::rbind.fill(removed, problem_censored)
rm(problem_censored)
dimCheck(all_result_num, dataset, removed, checkName = "Censored Data")
# display full table
nrow = length(unique(dataset$TADA.CharacteristicName))
# get table of characteristics with number of results, sites, and organizations
dataset%>%dplyr::group_by(TADA.CharacteristicName)%>%dplyr::summarise(Result_Count = length(ResultIdentifier), Site_Count = length(unique(MonitoringLocationIdentifier)), Org_Count = length(unique(OrganizationIdentifier)))%>%dplyr::arrange(desc(Result_Count))%>%print(n = nrow)
# go ahead and pick a characteristic name from the table generated above. I picked nitrogen, mixed forms
TADA::fieldValuesPie(dataset, field = "TADA.ResultSampleFractionText", characteristicName = "NITROGEN, MIXED FORMS (NH3), (NH4), ORGANIC, (NO2) AND (NO3)")
TADA::TADAOverviewMap(dataset)
TADA::fieldValuesPie(dataset, field = "MonitoringLocationTypeName")
# before...
TADA::fieldValuesTable(dataset, field = "TADA.ResultMeasure.MeasureUnitCode")%>%dplyr::arrange(desc(Count))
# convert units
dataset = TADA::ConvertResultUnits(dataset, transform = TRUE)
# after!
TADA::fieldValuesTable(dataset, field = "TADA.ResultMeasure.MeasureUnitCode")%>%dplyr::arrange(desc(Count))
qaqc_ref = TADA::GetWQXCharValRef()
head(qaqc_ref)
unique(qaqc_ref$Type)
dataset_flags = TADA::InvalidFraction(dataset, clean = FALSE, errorsonly = FALSE)
dataset_flags = TADA::InvalidSpeciation(dataset_flags, clean = "none", errorsonly = FALSE)
dataset_flags = TADA::InvalidResultUnit(dataset_flags, clean = "none", errorsonly = FALSE)
dataset_flags = TADA::QualityControlActivity(dataset_flags, clean = FALSE, errorsonly = FALSE)
dimCheck(all_result_num, dataset_flags, removed, checkName = "Run Flag Functions")
TADA::fieldValuesPie(dataset_flags, field = "TADA.SampleFraction.Flag")
TADA::fieldValuesPie(dataset_flags, field = "TADA.MethodSpeciation.Flag")
TADA::fieldValuesPie(dataset_flags, field = "TADA.ResultUnit.Flag")
TADA::fieldValuesPie(dataset_flags, field = "TADA.ActivityType.Flag")
# grab all the flagged results from the four functions
problem_flagged = dataset_flags%>%filter(TADA.SampleFraction.Flag=="Invalid"|TADA.MethodSpeciation.Flag=="Invalid"|TADA.ResultUnit.Flag=="Invalid"|!TADA.ActivityType.Flag%in%("Non_QC"))%>%dplyr::mutate(TADA.RemovedReason = "Invalid Unit, Method, Speciation, or Activity Type.")
dataset_flags = dataset_flags%>%dplyr::filter(!ResultIdentifier%in%problem_flagged$ResultIdentifier)
removed = plyr::rbind.fill(removed, problem_flagged)
rm(problem_flagged)
dimCheck(all_result_num, dataset_flags, removed, checkName = "Filter Flag Functions")
dataset_cens = TADA::simpleCensoredMethods(dataset_flags, nd_method = "multiplier",nd_multiplier = 0.5, od_method = "as-is")
# before
TADA::fieldValuesTable(dataset_flags, field = "TADA.ResultMeasureValueDataTypes.Flag")
# after
TADA::fieldValuesTable(dataset_cens, field = "TADA.ResultMeasureValueDataTypes.Flag")
# trusty field values table - lets just look at the first few entries with the most associated records
TADA::fieldValuesTable(dataset_cens, field = "TADA.ComparableDataIdentifier")%>%dplyr::arrange(desc(Count))%>%head()
# Look at a histogram, boxplot, and stats for TADA.ComparableDataIdentifier(s) of your choice.
comp_data_id = "TEMPERATURE, WATER_NA_NA_DEG C"
plot_data = subset(dataset_cens, dataset_cens$TADA.ComparableDataIdentifier%in%comp_data_id)
TADA::TADA_hist(plot_data, id_col = "TADA.ComparableDataIdentifier")
TADA::TADA_boxplot(plot_data, id_col = "TADA.ComparableDataIdentifier")
TADA::TADA_stats(plot_data)
table(removed$TADA.RemovedReason)
# check result numbers
all_result_num = dim(dataset_0)[1]
# remove data with media type that is not water
removed = dataset_0%>%dplyr::filter(!TADA.ActivityMediaName%in%c("WATER"))%>%dplyr::mutate(TADA.RemovedReason = "Activity media is not water.")
# what other media types exist in dataset?
unique(removed$TADA.ActivityMediaName)
# clean dataset contains only water
dataset = dataset_0%>%dplyr::filter(TADA.ActivityMediaName%in%c("WATER"))
dimCheck(all_result_num, dataset, removed, checkName = "Activity Media")
TADA::fieldValuesTable(dataset,field="ActivityTypeCode")
TADA::fieldValuesPie(dataset,field="ActivityTypeCode")
# take a look at datatypes
TADA::fieldValuesTable(dataset,field="TADA.ResultMeasureValueDataTypes.Flag")
# these are all of the NOT allowable data types in the dataset.
wrong_datatype = dataset%>%filter(!TADA.ResultMeasureValueDataTypes.Flag%in%c("Numeric","Less Than","Greater Than","Approximate Value","Percentage","Comma-Separated Numeric","Numeric Range - Averaged","Result Value/Unit Copied from Detection Limit"))%>%dplyr::mutate(TADA.RemovedReason = "Result value type cannot be converted to numeric or no detection limit values provided.")
# take a look at the difficult data types - do they make sense?
check = unique(wrong_datatype[,c("TADA.CharacteristicName","ResultMeasureValue","TADA.ResultMeasureValue", "ResultMeasure.MeasureUnitCode","TADA.ResultMeasure.MeasureUnitCode","TADA.ResultMeasureValueDataTypes.Flag","DetectionQuantitationLimitMeasure.MeasureValue","TADA.DetectionQuantitationLimitMeasure.MeasureValue", "DetectionQuantitationLimitMeasure.MeasureUnitCode","TADA.DetectionQuantitationLimitMeasure.MeasureUnitCode")])
dataset = dataset%>%filter(TADA.ResultMeasureValueDataTypes.Flag%in%c("Numeric","Less Than","Greater Than","Approximate Value","Percentage","Comma-Separated Numeric","Numeric Range - Averaged","Result Value/Unit Copied from Detection Limit"))
removed = plyr::rbind.fill(removed, wrong_datatype)
rm(wrong_datatype, check)
dimCheck(all_result_num, dataset, removed, checkName = "Result Format")
TADA::fieldValuesPie(dataset, field = "TADA.CensoredData.Flag")
problem_censored = dataset%>%dplyr::filter(!TADA.CensoredData.Flag%in%c("Non-Detect","Over-Detect","Other","Uncensored"))%>%dplyr::mutate(TADA.RemovedReason = "Detection limit information contains errors or missing information.")
dataset = dataset%>%dplyr::filter(TADA.CensoredData.Flag%in%c("Non-Detect","Over-Detect","Other", "Uncensored"))
removed = plyr::rbind.fill(removed, problem_censored)
rm(problem_censored)
dimCheck(all_result_num, dataset, removed, checkName = "Censored Data")
# defining a dimension check function that compares removed and retained data dimensions against the initial data input
dimCheck <- function(all_result_num, pass_data, fail_data, checkName){
# check result numbers after split
final_result_num = dim(pass_data)[1] + dim(fail_data)[1]
# always good to do a dimension check
if(!all_result_num==final_result_num){
print(paste0("Help! Results do not add up between dataset and removed after ",checkName," check."))
}else{print(paste0("Good to go. Zero results created or destroyed in ",checkName," check."))}
}
# check result numbers
all_result_num = dim(dataset_0)[1]
# remove data with media type that is not water
removed = dataset_0%>%dplyr::filter(!TADA.ActivityMediaName%in%c("WATER"))%>%dplyr::mutate(TADA.RemovedReason = "Activity media is not water.")
# what other media types exist in dataset?
unique(removed$TADA.ActivityMediaName)
# clean dataset contains only water
dataset = dataset_0%>%dplyr::filter(TADA.ActivityMediaName%in%c("WATER"))
dimCheck(all_result_num, dataset, removed, checkName = "Activity Media")
TADA::fieldValuesTable(dataset,field="ActivityTypeCode")
TADA::fieldValuesPie(dataset,field="ActivityTypeCode")
# take a look at datatypes
TADA::fieldValuesTable(dataset,field="TADA.ResultMeasureValueDataTypes.Flag")
# these are all of the NOT allowable data types in the dataset.
wrong_datatype = dataset%>%filter(!TADA.ResultMeasureValueDataTypes.Flag%in%c("Numeric","Less Than","Greater Than","Approximate Value","Percentage","Comma-Separated Numeric","Numeric Range - Averaged","Result Value/Unit Copied from Detection Limit"))%>%dplyr::mutate(TADA.RemovedReason = "Result value type cannot be converted to numeric or no detection limit values provided.")
# take a look at the difficult data types - do they make sense?
check = unique(wrong_datatype[,c("TADA.CharacteristicName","ResultMeasureValue","TADA.ResultMeasureValue", "ResultMeasure.MeasureUnitCode","TADA.ResultMeasure.MeasureUnitCode","TADA.ResultMeasureValueDataTypes.Flag","DetectionQuantitationLimitMeasure.MeasureValue","TADA.DetectionQuantitationLimitMeasure.MeasureValue", "DetectionQuantitationLimitMeasure.MeasureUnitCode","TADA.DetectionQuantitationLimitMeasure.MeasureUnitCode")])
dataset = dataset%>%filter(TADA.ResultMeasureValueDataTypes.Flag%in%c("Numeric","Less Than","Greater Than","Approximate Value","Percentage","Comma-Separated Numeric","Numeric Range - Averaged","Result Value/Unit Copied from Detection Limit"))
removed = plyr::rbind.fill(removed, wrong_datatype)
rm(wrong_datatype, check)
dimCheck(all_result_num, dataset, removed, checkName = "Result Format")
TADA::fieldValuesPie(dataset, field = "TADA.CensoredData.Flag")
problem_censored = dataset%>%dplyr::filter(!TADA.CensoredData.Flag%in%c("Non-Detect","Over-Detect","Other","Uncensored"))%>%dplyr::mutate(TADA.RemovedReason = "Detection limit information contains errors or missing information.")
dataset = dataset%>%dplyr::filter(TADA.CensoredData.Flag%in%c("Non-Detect","Over-Detect","Other", "Uncensored"))
removed = plyr::rbind.fill(removed, problem_censored)
rm(problem_censored)
dimCheck(all_result_num, dataset, removed, checkName = "Censored Data")
# display full table
nrow = length(unique(dataset$TADA.CharacteristicName))
# get table of characteristics with number of results, sites, and organizations
dataset%>%dplyr::group_by(TADA.CharacteristicName)%>%dplyr::summarise(Result_Count = length(ResultIdentifier), Site_Count = length(unique(MonitoringLocationIdentifier)), Org_Count = length(unique(OrganizationIdentifier)))%>%dplyr::arrange(desc(Result_Count))%>%print(n = nrow)
# go ahead and pick a characteristic name from the table generated above. I picked nitrogen, mixed forms
TADA::fieldValuesPie(dataset, field = "TADA.ResultSampleFractionText", characteristicName = "NITROGEN, MIXED FORMS (NH3), (NH4), ORGANIC, (NO2) AND (NO3)")
# before...
TADA::fieldValuesTable(dataset, field = "TADA.ResultMeasure.MeasureUnitCode")%>%dplyr::arrange(desc(Count))
# convert units
dataset = TADA::ConvertResultUnits(dataset, transform = TRUE)
# after!
TADA::fieldValuesTable(dataset, field = "TADA.ResultMeasure.MeasureUnitCode")%>%dplyr::arrange(desc(Count))
dataset_flags = TADA::InvalidFraction(dataset, clean = FALSE, errorsonly = FALSE)
dataset_flags = TADA::InvalidSpeciation(dataset_flags, clean = "none", errorsonly = FALSE)
dataset_flags = TADA::InvalidResultUnit(dataset_flags, clean = "none", errorsonly = FALSE)
dataset_flags = TADA::QualityControlActivity(dataset_flags, clean = FALSE, errorsonly = FALSE)
dimCheck(all_result_num, dataset_flags, removed, checkName = "Run Flag Functions")
TADA::fieldValuesPie(dataset_flags, field = "TADA.SampleFraction.Flag")
TADA::fieldValuesPie(dataset_flags, field = "TADA.MethodSpeciation.Flag")
TADA::fieldValuesPie(dataset_flags, field = "TADA.ResultUnit.Flag")
TADA::fieldValuesPie(dataset_flags, field = "TADA.ActivityType.Flag")
# grab all the flagged results from the four functions
problem_flagged = dataset_flags%>%filter(TADA.SampleFraction.Flag=="Invalid"|TADA.MethodSpeciation.Flag=="Invalid"|TADA.ResultUnit.Flag=="Invalid"|!TADA.ActivityType.Flag%in%("Non_QC"))%>%dplyr::mutate(TADA.RemovedReason = "Invalid Unit, Method, Speciation, or Activity Type.")
dataset_flags = dataset_flags%>%dplyr::filter(!ResultIdentifier%in%problem_flagged$ResultIdentifier)
removed = plyr::rbind.fill(removed, problem_flagged)
rm(problem_flagged)
dimCheck(all_result_num, dataset_flags, removed, checkName = "Filter Flag Functions")
table(removed$TADA.RemovedReason)
TADA::fieldValuesTable(removed, field = "TADA.RemovedReason")
unique(removed$DetectionQuantitationLimitTypeName)
remove.packages("TADAShiny")
remotes::install_github("USEPA/TADAShiny", ref = "filter_page_eh")
library(TADAShiny)
run_app()
TADAShiny::run_app()
remove.packages("TADAShiny")
remotes::install_github("USEPA/TADAShiny", ref = "filter_page_eh")
remove.packages("TADA")
setwd("C:/Users/ehinman/Documents/GitHub/tada-statfigs")
shiny::runApp('statfigs')
remotes::install_github("USEPA/TADA", ref = "develop")
